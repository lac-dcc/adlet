{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb65793d-2f5c-47d5-badc-9ae31a0e114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93896a-e967-49f0-9ec4-15013f08f792",
   "metadata": {},
   "source": [
    "![Image](bert-like-before.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76edb3-c68f-4f00-b2f2-fbc0525109d1",
   "metadata": {},
   "source": [
    "![Image](bert-like-after.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438d9e00-64ce-478f-9853-e329d074df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    (\"DD\", \"0\"),\n",
    "    (\"SparseDense\", \"0\"),\n",
    "    (\"SparseDense\", \"1\"),\n",
    "]\n",
    "sparsities = [\"0.10\", \"0.3\", \"0.5\", \"0.7\", \"0.9\"]\n",
    "\n",
    "repeats = 10\n",
    "binary = \"../../build/benchmark\"\n",
    "graph_name = \"bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3235efd2-729e-4e6b-9786-ace1e20a75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(output):\n",
    "    metrics = {}\n",
    "    lines = output.strip().splitlines()\n",
    "    for line in lines:\n",
    "        if \"analysis\" in line:\n",
    "            metrics[\"analysis\"] = float(line.split(\"=\")[-1].strip())\n",
    "        elif \"load graph\" in line:\n",
    "            metrics[\"load\"] = float(line.split(\"=\")[-1].strip())\n",
    "        elif \"compilation\" in line:\n",
    "            metrics[\"compilation\"] = float(line.split(\"=\")[-1].strip())\n",
    "        elif \"runtime\" in line:\n",
    "            metrics[\"runtime\"] = float(line.split(\"=\")[-1].strip())\n",
    "        elif \"memory used\" in line:\n",
    "            metrics[\"memory\"] = float(line.split(\"=\")[-1].strip())\n",
    "        elif \"before\" in line:\n",
    "            metrics[\"before\"] = float(line.split(\"=\")[-1].strip())\n",
    "        elif \"after\" in line:\n",
    "            metrics[\"after\"] = float(line.split(\"=\")[-1].strip())\n",
    "    return metrics\n",
    "\n",
    "def run():\n",
    "    results = []\n",
    "    with open(f\"{graph_name}-{datetime.now()}.out\", \"wt\") as file:\n",
    "        file.write(\"model, row, col, format, prop, before, after, analysis, load, comp, run, memory\\n\")\n",
    "        for fmt, opt in configs:\n",
    "            for sparsity in sparsities:\n",
    "                print(f\"{fmt}, {opt}, {sparsity}\",end='\\r')\n",
    "                times = {\"analysis\": [], \"load\": [], \"compilation\": [], \"runtime\": [], \"memory\": []}\n",
    "                for _ in range(repeats):\n",
    "                    cmd = [binary, \"graph\", graph_name, sparsity, sparsity, fmt, opt]\n",
    "                    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "                    metrics = parse_output(result.stdout)\n",
    "                    for k in times:\n",
    "                        times[k].append(metrics.get(k, 0.0))\n",
    "        \n",
    "                mean_metrics = {k: statistics.mean(times[k]) for k in times}\n",
    "                mean_metrics[\"config\"] = f\"{sparsity},{sparsity},{fmt},opt={opt}\"\n",
    "                file.write(f'{graph_name},{sparsity}, {sparsity}, {fmt}, {opt}, {metrics[\"before\"]}, {metrics[\"after\"]}, {mean_metrics[\"analysis\"]}, {mean_metrics[\"load\"]}, {mean_metrics[\"compilation\"]}, {mean_metrics[\"runtime\"]}, {mean_metrics[\"memory\"]}\\n')\n",
    "                results.append(mean_metrics)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fd44eb-a55f-46ca-b8e1-1f37c8053add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data):\n",
    "    # === Legend mapping ===\n",
    "    legend_map = {\n",
    "        \"SparseDense,opt=1\": \"sparse+prop\",\n",
    "        \"SparseDense,opt=0\": \"sparse\",\n",
    "        \"DD,opt=0\": \"dense\",\n",
    "    }\n",
    "\n",
    "    # === Organize data ===\n",
    "    configs = defaultdict(lambda: {\"ratios\": [], \"runtime\": [], \"memory\": [], \"analysis\": [], \"compilation\": []})\n",
    "    ratio_labels = []\n",
    "\n",
    "    for entry in data:\n",
    "        # Extract ratio and config name\n",
    "        parts = entry[\"config\"].split(\",\")\n",
    "        ratio = f\"({parts[0]},{parts[1]})\"\n",
    "        config_type = \",\".join(parts[2:])  # e.g., \"DD,opt=0\"\n",
    "        label = legend_map.get(config_type, config_type)\n",
    "\n",
    "        if ratio not in ratio_labels:\n",
    "            ratio_labels.append(ratio)\n",
    "\n",
    "        configs[label][\"ratios\"].append(ratio)\n",
    "        configs[label][\"runtime\"].append(entry[\"runtime\"])\n",
    "        configs[label][\"memory\"].append(entry[\"memory\"])\n",
    "        configs[label][\"analysis\"].append(entry[\"analysis\"])\n",
    "        configs[label][\"compilation\"].append(entry[\"compilation\"])\n",
    "\n",
    "    # Sort ratio_labels (by numeric value)\n",
    "    def ratio_key(r):\n",
    "        vals = r.strip(\"()\").split(\",\")\n",
    "        return float(vals[0]), float(vals[1])\n",
    "    ratio_labels = sorted(ratio_labels, key=ratio_key)\n",
    "\n",
    "    # Create index for x-axis\n",
    "    x = np.arange(len(ratio_labels))\n",
    "\n",
    "    # === 1) Runtime plot ===\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for label, values in configs.items():\n",
    "        # Align runtime values according to ratio_labels order\n",
    "        runtime_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"runtime\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        plt.plot(x, runtime_values, label=label)\n",
    "    plt.xticks(x, ratio_labels, rotation=45)\n",
    "    plt.ylabel(\"Runtime (s)\")\n",
    "    plt.title(\"Runtime vs Ratios\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"runtime_plot.png\")\n",
    "    #plt.close()\n",
    "    plt.plot()\n",
    "\n",
    "    # === 2) Memory plot ===\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for label, values in configs.items():\n",
    "        memory_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"memory\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        plt.plot(x, memory_values, label=label)\n",
    "    plt.xticks(x, ratio_labels, rotation=45)\n",
    "    plt.ylabel(\"Memory (MB)\")\n",
    "    plt.title(\"Memory Usage vs Ratios\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"memory_plot.png\")\n",
    "    plt.plot()\n",
    "    #plt.close()\n",
    "\n",
    "    # === 3) Analysis vs Compilation vs Runtime (bar chart) ===\n",
    "    width = 0.25\n",
    "    bar_positions = np.arange(len(ratio_labels))\n",
    "    \n",
    "    for label, values in configs.items():\n",
    "        if label != \"sparse+prop\":\n",
    "            continue\n",
    "        analysis_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"analysis\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        comp_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"compilation\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        runtime_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"runtime\"]), key=lambda x: ratio_key(x[0]))]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(bar_positions - width, analysis_values, width, label=\"analysis\")\n",
    "        plt.bar(bar_positions, comp_values, width, label=\"compilation\")\n",
    "        plt.bar(bar_positions + width, runtime_values, width, label=\"runtime\")\n",
    "        plt.xticks(bar_positions, ratio_labels, rotation=45)\n",
    "        plt.ylabel(\"Time (s)\")\n",
    "        plt.title(f\"Analysis vs Compilation vs Runtime ({label})\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(f\"time_breakdown_{label.replace('+','_')}.png\")\n",
    "        #plt.close()\n",
    "        plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d3c70e-ecd2-47bb-9747-fba192a3f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly(data):\n",
    "    legend_map = {\n",
    "        \"SparseDense,opt=1\": \"sparse+prop\",\n",
    "        \"SparseDense,opt=0\": \"sparse\",\n",
    "        \"DD,opt=0\": \"dense\",\n",
    "    }\n",
    "\n",
    "    configs = defaultdict(lambda: {\"ratios\": [], \"runtime\": [], \"memory\": [], \"analysis\": [], \"compilation\": []})\n",
    "    ratio_labels = []\n",
    "\n",
    "    for entry in data:\n",
    "        parts = entry[\"config\"].split(\",\")\n",
    "        ratio = f\"({parts[0]},{parts[1]})\"\n",
    "        config_type = \",\".join(parts[2:])\n",
    "        label = legend_map.get(config_type, config_type)\n",
    "\n",
    "        if ratio not in ratio_labels:\n",
    "            ratio_labels.append(ratio)\n",
    "\n",
    "        configs[label][\"ratios\"].append(ratio)\n",
    "        configs[label][\"runtime\"].append(entry[\"runtime\"])\n",
    "        configs[label][\"memory\"].append(entry[\"memory\"])\n",
    "        configs[label][\"analysis\"].append(entry[\"analysis\"])\n",
    "        configs[label][\"compilation\"].append(entry[\"compilation\"])\n",
    "\n",
    "    def ratio_key(r):\n",
    "        vals = r.strip(\"()\").split(\",\")\n",
    "        return float(vals[0]), float(vals[1])\n",
    "    ratio_labels = sorted(ratio_labels, key=ratio_key)\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=3, cols=1,\n",
    "                        shared_xaxes=False,\n",
    "                        vertical_spacing=0.15,\n",
    "                        subplot_titles=(\"Runtime vs Sparsity Ratio\",\n",
    "                                        \"Memory Usage vs Sparsity Ratio\",\n",
    "                                        \"Analysis vs Compilation vs Runtime\"))\n",
    "    fig.layout.template = \"plotly_white\"\n",
    "    # === 1) Runtime Plot (row 1) ===\n",
    "    for label, values in configs.items():\n",
    "        runtime_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"runtime\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=ratio_labels, y=runtime_values, mode=\"lines\", name=f\"Runtime ({label})\", legendgroup=\"runtime\"),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # === 2) Memory Plot (row 2) ===\n",
    "    for label, values in configs.items():\n",
    "        memory_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"memory\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=ratio_labels, y=memory_values, mode=\"lines\", name=f\"Memory ({label})\", legendgroup=\"memory\"),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # === 3) Analysis vs Compilation vs Runtime (Bars) (row 3) ===\n",
    "    # To avoid clutter, show aggregated bars (sum over configs)\n",
    "    for label, values in configs.items():\n",
    "        if label != \"sparse+prop\":\n",
    "            continue\n",
    "        analysis_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"analysis\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        comp_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"compilation\"]), key=lambda x: ratio_key(x[0]))]\n",
    "        runtime_values = [v for _, v in sorted(zip(values[\"ratios\"], values[\"runtime\"]), key=lambda x: ratio_key(x[0]))]\n",
    "\n",
    "        fig.update_yaxes(type=\"log\", row=3, col=1)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=f\"Analysis ({label})\", x=ratio_labels, y=analysis_values, legendgroup=\"bar\"),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=f\"Compilation ({label})\", x=ratio_labels, y=comp_values, legendgroup=\"bar\"),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=f\"Runtime ({label})\", x=ratio_labels, y=runtime_values, legendgroup=\"bar\"),\n",
    "            row=3, col=1\n",
    "        )\n",
    "\n",
    "    # Layout adjustments\n",
    "    fig.update_layout(\n",
    "        height=1000,\n",
    "        title_text=\"Benchmark Results\",\n",
    "        barmode='group',\n",
    "        legend_tracegroupgap=300\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Row/Col Sparsity Ratio\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Row/Col Sparsity Ratio\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Row/Col Sparsity Ratio\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Runtime (s)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Memory (MB)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Time (s)\", row=3, col=1)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fdeece-43e7-43dc-ac77-1ae996e16428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DD, 0, 0.30"
     ]
    }
   ],
   "source": [
    "data = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc4567-d38c-4c40-9c58-f74ca0f66b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0478db-c1ee-4f50-9510-4fc2c0e8ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
